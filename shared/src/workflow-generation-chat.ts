/**
 * Workflow Generation Chat Types
 *
 * Types for the chat-based workflow generation system with extended thinking support.
 * This enables gradual, conversational workflow creation through AI assistance.
 */

import type { JsonObject, JsonValue } from "./types";

// ============================================================================
// CHAT MESSAGE TYPES
// ============================================================================

/**
 * Role of a message in the generation chat
 */
export type GenerationChatRole = "user" | "assistant" | "system";

/**
 * A single message in the workflow generation chat
 */
export interface GenerationChatMessage {
    id: string;
    role: GenerationChatRole;
    content: string;
    /** Extended thinking content (for reasoning models) */
    thinking?: string;
    /** Whether thinking block is expanded in UI */
    thinkingExpanded?: boolean;
    /** Timestamp of the message */
    timestamp: string;
    /** Workflow plan if this message contains one */
    workflowPlan?: WorkflowPlan;
    /** Token counts for this message */
    tokenUsage?: {
        promptTokens: number;
        completionTokens: number;
        thinkingTokens?: number;
    };
}

// ============================================================================
// WORKFLOW PLAN TYPES
// ============================================================================

/**
 * A proposed node in the workflow plan
 */
export interface ProposedNode {
    /** Unique identifier for the node */
    id: string;
    /** Node type (llm, http, conditional, etc.) */
    type: string;
    /** Display label for the node */
    label: string;
    /** Node configuration */
    config: JsonObject;
    /** Suggested position on canvas */
    position?: { x: number; y: number };
    /** Node to connect to (for edges) */
    connectTo?: string | string[];
    /** Connection source handle */
    sourceHandle?: string;
    /** Brief description of what this node does */
    description?: string;
}

/**
 * A proposed edge in the workflow plan
 */
export interface ProposedEdge {
    id: string;
    source: string;
    target: string;
    sourceHandle?: string;
    targetHandle?: string;
    /** Label for conditional branches */
    label?: string;
}

/**
 * A complete workflow plan generated by AI
 */
export interface WorkflowPlan {
    /** Suggested workflow name */
    name: string;
    /** Workflow description */
    description: string;
    /** List of proposed nodes */
    nodes: ProposedNode[];
    /** List of proposed edges */
    edges: ProposedEdge[];
    /** Entry node ID */
    entryNodeId: string;
    /** Human-readable summary of the workflow */
    summary: string;
    /** Estimated node count by category */
    nodeCountByCategory?: Record<string, number>;
}

// ============================================================================
// API REQUEST/RESPONSE TYPES
// ============================================================================

/**
 * Request to send a message to the generation chat
 */
export interface GenerationChatRequest {
    /** User's message */
    message: string;
    /** Previous conversation history */
    conversationHistory: GenerationChatMessage[];
    /** LLM connection ID to use */
    connectionId: string;
    /** Model to use for generation */
    model: string;
    /** Whether to enable extended thinking */
    enableThinking: boolean;
    /** Token budget for thinking (min 1024) */
    thinkingBudget?: number;
}

/**
 * Response from initiating a generation chat message
 */
export interface GenerationChatInitResponse {
    /** Execution ID for streaming */
    executionId: string;
    /** Message ID for the assistant response */
    messageId: string;
}

/**
 * Response from the generation chat service
 */
export interface GenerationChatResponse {
    /** Assistant's response text */
    response: string;
    /** Thinking content if extended thinking was enabled */
    thinking?: string;
    /** Workflow plan if the AI generated one */
    workflowPlan?: WorkflowPlan;
    /** Suggested follow-up questions */
    suggestedQuestions?: string[];
    /** Token usage statistics */
    tokenUsage?: {
        promptTokens: number;
        completionTokens: number;
        thinkingTokens?: number;
        totalTokens: number;
    };
}

/**
 * Request to create a workflow from a plan
 */
export interface CreateWorkflowFromPlanRequest {
    /** The approved workflow plan */
    plan: WorkflowPlan;
    /** Optional folder ID to place the workflow in */
    folderId?: string;
}

/**
 * Response from creating a workflow from a plan
 */
export interface CreateWorkflowFromPlanResponse {
    /** Created workflow ID */
    workflowId: string;
    /** Workflow name */
    name: string;
    /** Success message */
    message: string;
}

// ============================================================================
// STREAMING EVENT TYPES
// ============================================================================

/**
 * Base interface for generation chat streaming events
 */
export interface GenerationChatStreamEvent {
    type: GenerationChatStreamEventType;
    executionId: string;
    messageId: string;
    timestamp: number;
}

/**
 * Types of streaming events for generation chat
 */
export type GenerationChatStreamEventType =
    | "generation:connected"
    | "generation:thinking:start"
    | "generation:thinking:token"
    | "generation:thinking:complete"
    | "generation:response:start"
    | "generation:response:token"
    | "generation:response:complete"
    | "generation:plan:detected"
    | "generation:error";

/**
 * Event emitted when streaming connection is established
 */
export interface GenerationConnectedEvent extends GenerationChatStreamEvent {
    type: "generation:connected";
}

/**
 * Event emitted when extended thinking starts
 */
export interface GenerationThinkingStartEvent extends GenerationChatStreamEvent {
    type: "generation:thinking:start";
}

/**
 * Event emitted for each thinking token
 */
export interface GenerationThinkingTokenEvent extends GenerationChatStreamEvent {
    type: "generation:thinking:token";
    token: string;
    sequence: number;
}

/**
 * Event emitted when thinking completes
 */
export interface GenerationThinkingCompleteEvent extends GenerationChatStreamEvent {
    type: "generation:thinking:complete";
    thinkingContent: string;
    tokenCount: number;
}

/**
 * Event emitted when response text starts
 */
export interface GenerationResponseStartEvent extends GenerationChatStreamEvent {
    type: "generation:response:start";
}

/**
 * Event emitted for each response token
 */
export interface GenerationResponseTokenEvent extends GenerationChatStreamEvent {
    type: "generation:response:token";
    token: string;
    sequence: number;
}

/**
 * Event emitted when response completes
 */
export interface GenerationResponseCompleteEvent extends GenerationChatStreamEvent {
    type: "generation:response:complete";
    finalResponse: string;
    tokenUsage?: {
        promptTokens: number;
        completionTokens: number;
        thinkingTokens?: number;
        totalTokens: number;
    };
}

/**
 * Event emitted when a workflow plan is detected in the response
 */
export interface GenerationPlanDetectedEvent extends GenerationChatStreamEvent {
    type: "generation:plan:detected";
    plan: WorkflowPlan;
}

/**
 * Event emitted on error
 */
export interface GenerationErrorEvent extends GenerationChatStreamEvent {
    type: "generation:error";
    error: string;
    partialContent?: string;
}

/**
 * Union type of all generation chat streaming events
 */
export type GenerationChatStreamEventUnion =
    | GenerationConnectedEvent
    | GenerationThinkingStartEvent
    | GenerationThinkingTokenEvent
    | GenerationThinkingCompleteEvent
    | GenerationResponseStartEvent
    | GenerationResponseTokenEvent
    | GenerationResponseCompleteEvent
    | GenerationPlanDetectedEvent
    | GenerationErrorEvent;

// ============================================================================
// THINKING CONFIGURATION TYPES
// ============================================================================

/**
 * Configuration for extended thinking
 */
export interface ThinkingConfig {
    /** Whether thinking is enabled */
    enabled: boolean;
    /** Token budget for thinking (min 1024) */
    budget: number;
    /** Provider-specific settings */
    providerConfig?: {
        /** Anthropic: type field for thinking */
        anthropicType?: "enabled";
        /** Google: thinking budget mode */
        geminiMode?: "auto" | "manual";
    };
}

/**
 * Thinking result from LLM response
 */
export interface ThinkingResult {
    /** The thinking content (may be summarized) */
    content: string;
    /** Number of tokens used for thinking */
    tokenCount: number;
    /** Whether content was summarized by provider */
    wasSummarized?: boolean;
    /** Provider that generated the thinking */
    provider: string;
    /** Model that generated the thinking */
    model: string;
}

// ============================================================================
// NODE CATALOG TYPES (for system prompt)
// ============================================================================

/**
 * Simplified node type info for generation prompts
 */
export interface NodeTypeInfo {
    type: string;
    category: string;
    description: string;
    configFields: string[];
    example?: JsonValue;
}

/**
 * Node catalog for workflow generation
 */
export const NODE_TYPE_CATALOG: NodeTypeInfo[] = [
    // AI/LLM Nodes
    {
        type: "llm",
        category: "AI",
        description: "Process text with LLM (OpenAI, Anthropic, Google, Cohere)",
        configFields: ["provider", "model", "systemPrompt", "prompt", "temperature", "maxTokens"]
    },
    {
        type: "vision",
        category: "AI",
        description: "Analyze or generate images using vision models",
        configFields: ["provider", "model", "operation", "imageInput", "prompt"]
    },
    {
        type: "embeddings",
        category: "AI",
        description: "Generate vector embeddings for semantic search",
        configFields: ["provider", "model", "input", "batchMode"]
    },
    {
        type: "router",
        category: "AI",
        description: "AI-powered classification and routing to branches",
        configFields: ["provider", "model", "prompt", "routes", "defaultRoute"]
    },
    {
        type: "kb-query",
        category: "AI",
        description: "Semantic search on knowledge bases",
        configFields: ["knowledgeBaseId", "queryText", "topK", "similarityThreshold"]
    },
    {
        type: "audioInput",
        category: "AI",
        description: "Speech-to-text transcription",
        configFields: ["provider", "model", "inputParameterName", "language"]
    },
    {
        type: "audioOutput",
        category: "AI",
        description: "Text-to-speech audio generation",
        configFields: ["provider", "model", "voice", "textInput", "outputFormat"]
    },

    // Input Nodes
    {
        type: "input",
        category: "Input",
        description: "Define workflow input parameters",
        configFields: ["variableName", "inputType", "description", "defaultValue"]
    },
    {
        type: "files",
        category: "Input",
        description: "Process uploaded documents with chunking",
        configFields: ["fileUpload", "chunkingAlgorithm", "chunkSize", "chunkOverlap"]
    },
    {
        type: "url",
        category: "Input",
        description: "Fetch and process web content",
        configFields: ["defaultUrls", "scrapingMode", "fetchTimeout", "chunkingAlgorithm"]
    },

    // Output Nodes
    {
        type: "output",
        category: "Output",
        description: "Define workflow output values",
        configFields: ["outputName", "format", "value", "description"]
    },
    {
        type: "templateOutput",
        category: "Output",
        description: "Render markdown/HTML templates with variables",
        configFields: ["outputName", "outputFormat", "templateContent"]
    },
    {
        type: "action",
        category: "Output",
        description: "Execute actions in external services (Slack, Gmail, etc.)",
        configFields: ["provider", "operation", "connectionId", "parameters"]
    },

    // Logic Nodes
    {
        type: "conditional",
        category: "Logic",
        description: "Binary branching based on conditions",
        configFields: ["conditionType", "leftValue", "operator", "rightValue"]
    },
    {
        type: "switch",
        category: "Logic",
        description: "Multi-way branching with pattern matching",
        configFields: ["inputVariable", "matchType", "cases", "defaultCase"]
    },
    {
        type: "loop",
        category: "Logic",
        description: "Iterate over collections (forEach, while, count)",
        configFields: ["loopType", "arrayVariable", "itemVariable", "maxIterations"]
    },
    {
        type: "wait",
        category: "Logic",
        description: "Delay workflow execution",
        configFields: ["waitType", "durationValue", "durationUnit", "timestamp"]
    },
    {
        type: "humanReview",
        category: "Logic",
        description: "Pause for human input (human-in-the-loop)",
        configFields: ["prompt", "variableName", "inputType", "required"]
    },
    {
        type: "transform",
        category: "Logic",
        description: "Data transformation (map, filter, reduce, etc.)",
        configFields: ["operation", "inputData", "expression"]
    },
    {
        type: "code",
        category: "Logic",
        description: "Execute custom JavaScript or Python code",
        configFields: ["language", "code", "timeout", "memoryLimit"]
    },
    {
        type: "shared-memory",
        category: "Logic",
        description: "Persistent key-value storage with semantic search",
        configFields: ["operation", "key", "value", "query"]
    },

    // Utility Nodes
    {
        type: "http",
        category: "Utility",
        description: "Make HTTP requests to APIs",
        configFields: ["method", "url", "headers", "body", "authentication"]
    },
    {
        type: "database",
        category: "Utility",
        description: "Execute database operations (PostgreSQL, MySQL, MongoDB)",
        configFields: ["databaseConnection", "operation", "query", "parameters"]
    },

    // Integration Nodes
    {
        type: "integration",
        category: "Integration",
        description: "Connect to third-party services (GitHub, Slack, HubSpot, etc.)",
        configFields: ["providerConnection", "operation", "parameters"]
    },
    {
        type: "fileOperations",
        category: "Integration",
        description: "File storage operations (GCS, S3)",
        configFields: ["operation", "storagePath", "fileContent"]
    }
];

/**
 * Get node types by category
 */
export function getNodeTypesByCategory(): Record<string, NodeTypeInfo[]> {
    const byCategory: Record<string, NodeTypeInfo[]> = {};
    for (const node of NODE_TYPE_CATALOG) {
        if (!byCategory[node.category]) {
            byCategory[node.category] = [];
        }
        byCategory[node.category].push(node);
    }
    return byCategory;
}

/**
 * Get a formatted node catalog string for system prompts
 */
export function getNodeCatalogForPrompt(): string {
    const byCategory = getNodeTypesByCategory();
    const lines: string[] = [];

    for (const [category, nodes] of Object.entries(byCategory)) {
        lines.push(`\n## ${category} Nodes`);
        for (const node of nodes) {
            lines.push(`- **${node.type}**: ${node.description}`);
            lines.push(`  Config: ${node.configFields.join(", ")}`);
        }
    }

    return lines.join("\n");
}
